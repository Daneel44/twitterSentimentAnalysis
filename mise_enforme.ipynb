{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "all=pd.read_csv(\"imdb.csv\",encoding='unicode_escape')\n",
    "all=all.loc[all['label']!=\"unsup\"]\n",
    "X_test=(all.loc[all['type']=='test']).loc[:,['review']]\n",
    "y_test=(all.loc[all['type']=='test']).loc[:,['label']]\n",
    "\n",
    "X_train=(all.loc[all['type']=='train']).loc[:,['review']]\n",
    "y_train=(all.loc[all['type']=='train']).loc[:,['label']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizing reviews\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "punc = '''!()-[]{};:'\"\\, <>./?@#$%^&*_~`'''\n",
    "test_reviews=X_test.to_dict()\n",
    "train_reviews=X_train.to_dict()\n",
    "\n",
    "#print(test_reviews['review'])\n",
    "def tokenizing(rev):\n",
    " tokens = nltk.word_tokenize(rev)\n",
    " stop_words = set(stopwords.words('english'))\n",
    " tokens_l = [w.lower() for w in tokens]\n",
    " token_final=[]\n",
    " for item in tokens_l : \n",
    "  item= item.strip(punc)\n",
    "  if item not in stop_words and item !=\"\":\n",
    "   token_final.append(item)\n",
    " text = nltk.Text(tokens)\n",
    " final_text=\"\"\n",
    " for wd in token_final:\n",
    "  final_text=final_text+wd+\" \" \n",
    " #only_nn = [x for (x,y) in token_final if y in ('NN')]\n",
    " #match = text.concordance('language')\n",
    " return [final_text, token_final]\n",
    "\n",
    "actual_test_text=dict()\n",
    "for x in test_reviews['review']:\n",
    " #print(x)\n",
    " #print(test_reviews['review'][x])\n",
    " actual_review=test_reviews['review'][x]\n",
    " txt=tokenizing(actual_review)[0]\n",
    " actual_test_text[x]=txt\n",
    "\n",
    "actual_train_text=dict()\n",
    "for x in train_reviews['review']:\n",
    " #print(x)\n",
    " #print(test_reviews['review'][x])\n",
    " actual_review=train_reviews['review'][x]\n",
    " txt=tokenizing(actual_review)[0]\n",
    " actual_train_text[x]=txt\n",
    "\n",
    " #print(actual_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_test[\"label\"])\n",
    "y_test=le.transform(y_test[\"label\"])\n",
    "\n",
    "le.fit(y_train[\"label\"])\n",
    "y_train=le.transform(y_train[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer# Create feature vectors\n",
    "df_test_text=pd.DataFrame.from_dict(actual_test_text, orient=\"index\", columns=[\"review\"])\n",
    "df_train_text=pd.DataFrame.from_dict(actual_train_text, orient=\"index\", columns=[\"review\"])\n",
    "#print(df_test_text.all)\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=2000,\n",
    "                             min_df = 5,\n",
    "                             max_df = 0.8,\n",
    "                             sublinear_tf = True,\n",
    "                             use_idf = True)\n",
    "x_train_vectors = vectorizer.fit_transform(df_train_text['review']).toarray()\n",
    "x_test_vectors = vectorizer.transform(df_test_text['review']).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.06155073 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "[0 0 0 ... 1 1 1]\n",
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.07950486 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "[0 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(x_train_vectors)\n",
    "print(y_train)\n",
    "print(x_test_vectors)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=0.1)\n",
    "clf.fit(x_train_vectors, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0     0 12500]\n",
      " [    0     0 12500]\n",
      " [    0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00   12500.0\n",
      "           1       0.00      0.00      0.00   12500.0\n",
      "           2       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00   25000.0\n",
      "   macro avg       0.00      0.00      0.00   25000.0\n",
      "weighted avg       0.00      0.00      0.00   25000.0\n",
      "\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonh/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jonh/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jonh/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jonh/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jonh/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jonh/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "pred=clf.predict(x_test_vectors)\n",
    "print(confusion_matrix(y_test,pred))  \n",
    "print(classification_report(y_test,pred))  \n",
    "print(accuracy_score(y_test, pred))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
